\title {Accelerating Spike-by-Spike Neural Networks with Approximate Dot-Product on FPGA}

\author{
	\uppercase{Yarib Nevarez}\authorrefmark{1},	
	\uppercase{David Rotermund}\authorrefmark{2},
	\uppercase{Klaus R. Pawelzik}\authorrefmark{3},
	\uppercase{Alberto Garcia-Ortiz}\authorrefmark{4} \IEEEmembership{Member, IEEE},
}

\address[1]{Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen 28359, Germany (e-mail: nevarez@item.uni-bremen.de)}

\address[2]{Institute for Theoretical Physics, University of Bremen, Bremen 28359, Germany (e-mail: davrot@@neuro.uni-bremen.de)}

\address[3]{Institute for Theoretical Physics, University of Bremen, Bremen 28359, Germany (e-mail: pawelzik@@neuro.uni-bremen.de)}

\address[4]{Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen 28359, Germany (e-mail: agaracia@item.uni-bremen.de)}

\tfootnote{This work is funded by the Consejo Nacional de Ciencia
	y Tecnologia - CONACYT (the Mexican National Council for
	Science and Technology)}

\markboth
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Yarib Nevarez (e-mail: nevarez@item.uni-bremen.de).}
.

\begin{abstract}
The Spike-by-Spike (SbS) neural network algorithm is a powerful machine learning (ML) technique for image classification with an exceptional noise robustness. However, deep SbS networks represent an elevated memory footprint and computational cost for profitable implementation in embedded applications. As an alternative, based on the intrinsic error-resilience of neural networks, approximate computing is a promising approach for resource-efficient deployment of neural networks in resource-constrained devices. In this paper, we accelerate SbS neural networks with a dot-product hardware unit based on approximate computing with quality configurable design. This approach reduces computational latency, memory footprint, and power dissipation while preserving accuracy. For output quality monitoring, we propose a noise tolerance plot to intuitively visualize the impact of approximation effects on inference accuracy. To demonstrate our approach, we address a design exploration flow using high-level synthesis and a Xilinx FPGA. As a result, the proposed design achieves up to $20.49\times$ latency enhancement, $8\times$ synaptic memory footprint reduction, and less than $0.5\%$ of accuracy degradation on handwritten digit recognition task.
	
\end{abstract}

\begin{keywords}
Artificial intelligence, spiking neural networks, approximate computing, logarithmic, parameterisable floating-point, optimization, hardware accelerator, embedded systems, FPGA
\end{keywords}

\titlepgskip=-15pt

\maketitle
