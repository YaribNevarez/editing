\section{Background}
\label{sec:background}
\input{../content/sbs_networks.tex}


\begin{algorithm}
\caption{SbS layer update.}

\begin{algorithmic}[1]
	\SetAlgoLined
	\renewcommand{\algorithmicrequire}{\textbf{input:}}
	\renewcommand{\algorithmicensure}{\textbf{output:}}
	\REQUIRE Layer as $L\in\mathbb{R}^{L_W \times L_H \times N}$, where\\
	$L_W$ is the layer width,\\
	$L_H$ is the layer height\\
	$N$ is length of IP vectors.
	\REQUIRE Synaptic matrix as $W\in\mathbb{R}^{K\times K\times M\times N}$, where\\
	$K \times K$ is the size of the convolution kernel, \\
	$M$ is the length of IP vectors from a previous layer,\\
	$N$ is the length of IP vectors of the self layer.  
	\REQUIRE Input spikes from a previous layer as $S_t^{in}\in\mathbb{N}^{ L_{W_{in}} \times L_{H_{in}}}$, where\\
	$L_{W_{in}}$ is the width of the previous layer,\\
	$L_{H_{in}}$ is the height of the previous layer
	
	\REQUIRE Epsilon as $\epsilon\in\mathbb{R}$
	\ENSURE Updated self layer as $L^{new}\in\mathbb{R}^{L_W\times L_H \times N}$\\
	\ENSURE Output spikes from self layer as $S_t^{out} \in\mathbb{N}^{L_W\times L_H}$
	\\
	\textit{Update layer} :
	\FOR {$L_X \leftarrow 0, L_Y \leftarrow 0$ \textbf{to} $L_{W} - 1,L_{H} - 1$}
		\textit{Generate spike} :
		
		\STATE $th \leftarrow MT19937PseudoRandom()$
		\STATE $acu \leftarrow 0$
		\FOR {$idx \leftarrow 0$ \textbf{to} $N-1$}
			\IF {$th \leq acu$ \textbf{or} $idx = N-1$}
				\STATE $S_t^{out}(L_X,L_Y) \leftarrow idx$
				\STATE \textbf{goto} \emph{Update IP}
			\ENDIF
			\STATE $acu \leftarrow acu + \vec{h}_{\mu}(idx)$
		\ENDFOR

		\textit{Update IP} :
		\STATE $\vec{h}_\mu \leftarrow L(L_X,L_Y)$ 
		\FOR {$K_X \leftarrow 0, K_Y \leftarrow 0$ \textbf{to} $K - 1,K - 1$}
		
			\STATE $s_t \leftarrow S_t^{in}(L_X+K_X,L_Y+K_Y)$
			\STATE $\vec{w} \leftarrow W(K_X,K_Y,s_t)$
			\STATE $\vec{p} \leftarrow 0$
			
			\textit{Dot-product} :
			\STATE $r_{\mu} \leftarrow 0$
			\FOR {$j \leftarrow 0$ \textbf{to} $N-1$}
				\STATE $\vec{p}(j) \leftarrow \vec{h}_{\mu}(j)\vec{w}(j)$
				\STATE $r_{\mu} \leftarrow r_{\mu} + \vec{p}(j)$
			\ENDFOR
			
			
			\IF {$r_{\mu} \ne 0$}
				\textit{Update IP vector} :
				\FOR {$i \leftarrow0$ \textbf{to} $N-1$}
				\STATE
				$  h_\mu^{new}(i) \leftarrow \frac{1}{1+\epsilon} \left(h_\mu(i) + \epsilon \frac{\vec{p}(i) }{r_{\mu}} \right) $
				\ENDFOR

				\textit{Set the new IP vector on the layer} :
				\STATE $L^{new}(L_X,L_Y) \leftarrow \vec{h}_\mu^{new}$
			\ENDIF
		\ENDFOR
	\ENDFOR
	
\end{algorithmic} 
\end{algorithm}

