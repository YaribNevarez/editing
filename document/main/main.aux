\relax 
\citation{schmidhuber2015deep,Taigman_2014_CVPR}
\citation{Design_Exploration_SbS_Trans20}
\citation{Spinnaker_Trans13,ernst2007efficient,Design_Exploration_SbS_Trans20,SNN_Survey_Trans19}
\citation{mcdonnell2011benefits}
\citation{mcdonnell2011benefits}
\citation{mcdonnell2011benefits}
\citation{mcdonnell2011benefits}
\citation{mcdonnell2011benefits}
\citation{ernst2007efficient,Dapello2020.06.16.154542}
\citation{ernst2007efficient,Dapello2020.06.16.154542}
\citation{ernst2007efficient,Dapello2020.06.16.154542}
\citation{ernst2007efficient,Dapello2020.06.16.154542}
\citation{ernst2007efficient,Dapello2020.06.16.154542}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{TrueNorth_Trans15}
\citation{TrueNorth_Trans15}
\citation{TrueNorth_Trans15}
\citation{TrueNorth_Trans15}
\citation{TrueNorth_Trans15}
\citation{Spinnaker_Trans13}
\citation{Spinnaker_Trans13}
\citation{Spinnaker_Trans13}
\citation{Spinnaker_Trans13}
\citation{Spinnaker_Trans13}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\citation{izhikevich2004model,amunts2019human}
\citation{izhikevich2004model,amunts2019human}
\citation{izhikevich2004model,amunts2019human}
\citation{izhikevich2004model,amunts2019human}
\citation{izhikevich2004model,amunts2019human}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{rotermund2019Backpropagation,ernst2007efficient}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{rotermund2019Backpropagation}
\citation{roy2019towards,bouvier2019spiking,young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}
\citation{roy2019towards,bouvier2019spiking,young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}
\citation{roy2019towards,bouvier2019spiking,young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}
\citation{roy2019towards,bouvier2019spiking,young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}
\citation{roy2019towards,bouvier2019spiking,young2019review,TrueNorth_Trans15,Spinnaker_Trans13,davies2018loihi}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator,rotermund2018massively}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{ernst2007efficient,rotermund2019recurrentsbs}
\citation{ernst2007efficient,rotermund2019recurrentsbs}
\citation{ernst2007efficient,rotermund2019recurrentsbs}
\citation{ernst2007efficient,rotermund2019recurrentsbs}
\citation{ernst2007efficient,rotermund2019recurrentsbs}
\citation{zhang2018survey}
\citation{lotrivc2012applicability,sarwar2016multiplier,mrazek2016design,du2014leveraging}
\citation{park2009dynamic,han2013approximate}
\citation{gupta2011impact,mittal2016survey}
\citation{venkataramani2015approximate}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Dot-product hardware module with (a) standard floating-point (IEEE 754) arithmetic, (b) hybrid custom floating-point approximation, and (c) hybrid logarithmic approximation.}}{2}}
\newlabel{fig:dot_product_unit}{{1}{2}}
\citation{han2013approximate}
\citation{bouvier2019spiking}
\citation{courbariaux2015binaryconnect,han2015deep,hubara2017quantized,rastegari2016xnor}
\citation{moons20160,whatmough201714}
\citation{rastegari2016xnor}
\citation{sun2018xnor}
\citation{lecun1989optimal,hassibi1992second}
\citation{molchanov2016pruning,li2016pruning,liu2018rethinking}
\citation{rathi2018stdp}
\citation{sen2017approximate}
\citation{srivastava2014dropout,wan2013regularization}
\citation{neftci2016stochastic,srinivasan2016magnetic}
\citation{buesing2011neural}
\citation{bellec2017deep,chen20184096}
\citation{sheik2016synaptic}
\citation{jerry2017ultra}
\citation{zhang2018survey}
\citation{han2013approximate}
\citation{kim2013energy}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related work}{3}}
\newlabel{sec:related_work}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Approximate computing in neural networks}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}1}Network compression}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}2}Classical approximate computing}{3}}
\citation{he2016deep}
\citation{russakovsky2015imagenet}
\citation{rastegari2016xnor}
\citation{rotermund2018massively}
\citation{nevarez2020accelerator}
\citation{ernst2007efficient}
\citation{ernst2007efficient}
\citation{rotermund2019Backpropagation}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Spike-by-Spike neural networks accelerators}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Background}{4}}
\newlabel{sec:background}{{III}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Spike-by-Spike Neural Networks}{4}}
\newlabel{sec:sbs}{{\unhbox \voidb@x \hbox {III-A}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SbS network architecture for handwritten digit classification task.}}{4}}
\newlabel{fig:sbs_network}{{2}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces SbS network architecture for handwritten digit classification task.}}{4}}
\newlabel{tab:sbs_network}{{1}{4}}
\newlabel{eq:sbs_update}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}\texthl  {Basic Network Overview}}{4}}
\citation{dayan2001theoretical}
\citation{dayan2001theoretical}
\citation{dayan2001theoretical}
\citation{dayan2001theoretical}
\citation{dayan2001theoretical}
\citation{lecun1998mnist}
\citation{rotermund2019Backpropagation}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\newlabel{alg:sbs}{{1}{5}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces SbS algorithm.}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces SbS IPs as independent computational entities, (a) illustrates an input layer with a massive amount of IPs operating as independent computational entities, (b) shows a hidden layer with an arbitrary amount of IPs as independent computational entities, (c) exhibits a set of neurons grouped in an IP.}}{5}}
\newlabel{fig:SbS_layer}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}\texthl  {Computational cost}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (a) Performance classification of SbS NN versus equivalent CNN, and (b) example of the first pattern in the MNIST test data set with different amounts of \texthl  {positive additive uniformly distributed noise}.}}{5}}
\newlabel{fig:robustnes_sbs}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}\texthl  {Error resilience}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}System Design}{5}}
\newlabel{sec:system_design}{{IV}{5}}
\citation{rotermund2019Backpropagation}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces System-level overview of the embedded software architecture.}}{6}}
\newlabel{fig:sw_stack}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Hardware architecture}{6}}
\newlabel{Hardware_architecture}{{\unhbox \voidb@x \hbox {IV-A}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces System-level hardware architecture with scalable number of heterogeneous PUs: {\it  Spike}, {\it  Conv}, {\it  Pool}, and {\it  FC}}}{6}}
\newlabel{fig:hw_sbs}{{6}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Conv processing unit}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}1}Configuration mode}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}2}Computation mode}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}dot-product hardware module}{7}}
\newlabel{sec:dot-product_hardware_module}{{\unhbox \voidb@x \hbox {IV-C}}{7}}
\newlabel{eq:dot_product}{{2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The {\it  Conv} processing unit and its six stages: (a) receive IP vector, (b) spike firing, (c) receive spike kernel, (d) update dynamics, (e) dispatch new IP vector, (f) dispatch output spike matrix.}}{7}}
\newlabel{fig:hw_conv}{{7}{7}}
\newlabel{eq:exp_max}{{3}{7}}
\newlabel{eq:bits_exp}{{4}{7}}
\newlabel{eq:bits_bitwidth}{{5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Dot-product hardware module with (a) hybrid custom floating-point approximation, and (b) hybrid logarithmic approximation.}}{8}}
\newlabel{fig:product_unit_bitwidth}{{8}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}1}Dot-product with standard floating-point computation}{8}}
\newlabel{eq:dot_standard_float_latency}{{6}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}2}Dot-product with hybrid custom floating-point and logarithmic approximation}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Dot-product hardware module with standard floating-point (IEEE 754) computation, (a) exhibits the initiation interval of 10 clock cycles, (b) presents the iteration latency of 19 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation block in light-gray.}}{8}}
\newlabel{fig:dot_product_float}{{9}{8}}
\citation{xilinx2015zynq}
\citation{nevarez2020accelerator}
\newlabel{eq:dot_standard_custom_float_latency}{{7}{9}}
\newlabel{eq:dot_log_latency}{{8}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Dot-product hardware module with hybrid custom floating-point approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 13 clock cycles, (c) shows the pairwise product blocks in dark-gray, and (d) illustrates the accumulation blocks in light-gray.}}{9}}
\newlabel{fig:dot_product_custom}{{10}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental results}{9}}
\newlabel{sec:experimental_results}{{V}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Dot-product hardware module with hybrid logarithmic approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 9 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation blocks in light-gray.}}{10}}
\newlabel{fig:dot_product_log}{{11}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Performance benchmark}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-A}1}Benchmark on embedded CPU}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-A}2}Benchmark on processing units with standard floating-point computation}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Computation on embedded CPU.}}{10}}
\newlabel{tab:latency_sw}{{2}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Computation on embedded CPU.}}{10}}
\newlabel{fig:latency_sw}{{12}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces System overview of the top-level architecture with 8 processing units.}}{10}}
\newlabel{fig:hw_sbs_8_pu}{{13}{10}}
\citation{hrica2012floating}
\citation{hrica2012floating}
\citation{hrica2012floating}
\citation{hrica2012floating}
\citation{hrica2012floating}
\citation{hrica2012floating}
\citation{hrica2012floating}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.}}{11}}
\newlabel{tab:latency_fp}{{3}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.}}{11}}
\newlabel{fig:latency_pu_fp}{{14}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Performance bottleneck of cyclic computation on processing units with standard floating-point (IEEE 754) arithmetic, (a) exhibits the starting of $t_{PU}$ of {\it  Conv2} on a previous computation cycle, (b) presents $t_{CPU}$ of {\it  Conv2} on the current computation cycle, (c) shows the CPU waiting time (in gray color) for {\it  Conv2} as a busy resource (awaiting for {\it  Conv2} interruption), and (d) illustrates the $t_{f}$ from the previous computation cycle, the starting of $t_{PU}$ on the current computation cycle ({\it  Conv2} interruption on completion, and start current computation cycle).}}{11}}
\newlabel{fig:latency_pu_fp_cycle}{{15}{11}}
\newlabel{eq:time_cpu}{{9}{11}}
\newlabel{eq:time_pu}{{10}{11}}
\newlabel{eq:time_spike}{{11}{11}}
\newlabel{eq:time_finish}{{12}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Resource utilization and power dissipation of processing units with standard floating-point (IEEE 754) computation.}}{11}}
\newlabel{tab:resource_fp}{{4}{11}}
\citation{venkataramani2015approximate}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores.}}{12}}
\newlabel{tab:LogiCORE}{{5}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-A}3}Benchmark on noise tolerance plot}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Design exploration with hybrid custom floating-point and logarithmic approximation}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-B}1}Parameters for numeric representation of synaptic weight matrix}{12}}
\newlabel{sec:parameters}{{\unhbox \voidb@x \hbox {V-B}1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Noise tolerance on hardware PU with standard floating-point (IEEE 754) computation (benchmark/reference), (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.}}{12}}
\newlabel{fig:accuracy_vs_noise_pu_fp}{{16}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces $\qopname  \relax o{log}_2$-histogram of each synaptic weight matrix showing the percentage of matrix elements with given integer exponent.}}{13}}
\newlabel{fig:log2histogram}{{17}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-B}2}Design exploration for dot-product with hybrid custom floating-point approximation}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Performance on processing units with hybrid custom floating-point approximation, (a) exhibits computation schedule, (b) presents cyclic computation schedule, and (c) shows the performance of {\it  Conv2} from a previous computation cycle during the preprocessing of {\it  H1\_CONV} on the current computation cycle without bottleneck.}}{13}}
\newlabel{fig:latency_pu_cfp_cycle}{{18}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid custom floating-point approximation.}}{13}}
\newlabel{tab:resource_cfp}{{6}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-B}3}Design exploration for dot-product whit hybrid logarithmic approximation}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Performance of hardware processing units with hybrid custom floating-point approximation.}}{14}}
\newlabel{tab:latency_cfp}{{7}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Noise tolerance on hardware PU with custom floating-point approximation, (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.}}{14}}
\newlabel{fig:accuracy_vs_noise_pu_cfp}{{19}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Performance of hardware processing units with hybrid logarithmic approximation.}}{14}}
\newlabel{tab:latency_log}{{8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Performance of processing units with hybrid logarithmic approximation, (a) exhibits computation schedule, and (b) illustrates cyclic computation schedule.}}{14}}
\newlabel{fig:latency_pu_log_cycle}{{20}{14}}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\citation{nevarez2020accelerator}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid logarithmic approximation.}}{15}}
\newlabel{tab:resource_log}{{9}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Noise tolerance on hardware PU with hybrid logarithmic approximation, (a) exhibits accuracy degradation applying $40\%$ of noise amplitude, (b) illustrates convergence of inference with $600$ spikes.}}{15}}
\newlabel{fig:accuracy_vs_noise_pu_log}{{21}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Results and discussion}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{15}}
\newlabel{sec:conclusions}{{VI}{15}}
\bibstyle{IEEEtran}
\bibdata{../content/bibliography.bib}
\bibcite{schmidhuber2015deep}{1}
\bibcite{Taigman_2014_CVPR}{2}
\bibcite{Design_Exploration_SbS_Trans20}{3}
\bibcite{Spinnaker_Trans13}{4}
\bibcite{ernst2007efficient}{5}
\bibcite{SNN_Survey_Trans19}{6}
\bibcite{mcdonnell2011benefits}{7}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Experimental results.}}{16}}
\newlabel{tab:results}{{10}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Platform implementations.}}{16}}
\newlabel{tab:platform_comparison}{{11}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Power dissipation breakdown of platform implementations, (a) Ref. \cite  {nevarez2020accelerator} architecture with homogeneous AUs using standard floating-point arithmetic (IEEE 754), (b) reference architecture with specialized heterogeneous PUs using standard floating-point arithmetic (IEEE 754), (c) proposed architecture with hybrid custom floating-point approximation, and (d) proposed architecture with hybrid logarithmic approximation.}}{16}}
\newlabel{fig:platform_power_dissipation_breakdown}{{22}{16}}
\newlabel{sec:Ack}{{VI}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}\texthl  {SbS algorithm}}{16}}
\newlabel{sec:appendix_sbs_algorithm}{{\unhbox \voidb@x \hbox {VI-A}}{16}}
\@writefile{toc}{\contentsline {section}{REFERENCES}{16}}
\bibcite{Dapello2020.06.16.154542}{8}
\bibcite{davies2018loihi}{9}
\bibcite{TrueNorth_Trans15}{10}
\newlabel{alg:inference}{{2}{17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces SbS network inference.}}{17}}
\newlabel{alg:spike}{{3}{17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Spike production.}}{17}}
\newlabel{alg:update}{{4}{17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces SbS layer update.}}{17}}
\bibcite{izhikevich2004model}{11}
\bibcite{amunts2019human}{12}
\bibcite{rotermund2019Backpropagation}{13}
\bibcite{nevarez2020accelerator}{14}
\bibcite{rotermund2018massively}{15}
\bibcite{roy2019towards}{16}
\bibcite{bouvier2019spiking}{17}
\bibcite{young2019review}{18}
\bibcite{rotermund2019recurrentsbs}{19}
\bibcite{zhang2018survey}{20}
\bibcite{lotrivc2012applicability}{21}
\bibcite{sarwar2016multiplier}{22}
\bibcite{mrazek2016design}{23}
\bibcite{du2014leveraging}{24}
\bibcite{park2009dynamic}{25}
\bibcite{han2013approximate}{26}
\bibcite{gupta2011impact}{27}
\bibcite{mittal2016survey}{28}
\bibcite{venkataramani2015approximate}{29}
\bibcite{courbariaux2015binaryconnect}{30}
\bibcite{han2015deep}{31}
\bibcite{hubara2017quantized}{32}
\bibcite{rastegari2016xnor}{33}
\bibcite{moons20160}{34}
\bibcite{whatmough201714}{35}
\bibcite{sun2018xnor}{36}
\bibcite{lecun1989optimal}{37}
\bibcite{hassibi1992second}{38}
\bibcite{molchanov2016pruning}{39}
\bibcite{li2016pruning}{40}
\bibcite{liu2018rethinking}{41}
\bibcite{rathi2018stdp}{42}
\bibcite{sen2017approximate}{43}
\bibcite{srivastava2014dropout}{44}
\bibcite{wan2013regularization}{45}
\bibcite{neftci2016stochastic}{46}
\bibcite{srinivasan2016magnetic}{47}
\bibcite{buesing2011neural}{48}
\bibcite{bellec2017deep}{49}
\bibcite{chen20184096}{50}
\bibcite{sheik2016synaptic}{51}
\bibcite{jerry2017ultra}{52}
\bibcite{kim2013energy}{53}
\bibcite{he2016deep}{54}
\bibcite{russakovsky2015imagenet}{55}
\bibcite{dayan2001theoretical}{56}
\bibcite{lecun1998mnist}{57}
\bibcite{xilinx2015zynq}{58}
\bibcite{hrica2012floating}{59}
\@writefile{toc}{\contentsline {subsection}{Yarib Nevarez}{19}}
\@writefile{toc}{\contentsline {subsection}{David Rotermund}{19}}
\@writefile{toc}{\contentsline {subsection}{Klaus R. Pawelzik}{19}}
\@writefile{toc}{\contentsline {subsection}{Alberto Garcia-Ortiz}{19}}
