\section{Related work}
\label{sec:related_work}
\subsection{TensorFlow models on the Google's Edge TPU}

The Edge Tensor Processing Unit (TPU) is an ASIC designed by Google that provides high performance machine learning (ML) inference for TensorFlow Lite models\cite{yazdanbakhsh2021evaluation}. This implementation uses PCIe and I2C/GPIO to interface with an iMX 8M SoC. The reported throughput and power efficiency are 4 trillion operations per second (TOPS) and 2 TOPS per watt, respectively \cite{coral2021Datasheet}. The Edge TPU supports 40 tensor operators including Conv2d and DepthwiseConv2d \cite{coral2021Compatibility}.

However, the Edge TPU has disadvantages.
\begin{itemize}
	\item Power dissipation. The Edge TPU System-on-Module (SoM) requires 2 to 3A at 5V DC power supply\cite{coral2021Datasheet}, which can be unsuitable for very low-power applications.
	\item Model compatibility. It supports only TensorFlow Lite models that are fully 8-bit quantized and then compiled specifically for the Edge TPU \cite{cass2019taking}. The 8-bit quantization method requires a representative dataset that can be inaccessible, which limits its usability.
\end{itemize}